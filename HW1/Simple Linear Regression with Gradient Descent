import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
import pandas as pd


#get from CSV
df = pd.read_csv('polydata.csv')
x = df['x']
y = df['y']
plt.plot(x,y, 'o')

#3 Split dataset
X_train = x[0:80]
X_test = x[80:100]
Y_train = y[0:80]
Y_test = y[80:100]

i=0
while i <= 10:
  poly = PolynomialFeatures(degree=i)
  x_poly = poly.fit_transform(df)
  model = LinearRegression()
  model.fit(x_poly, y)
  y_pred = model.predict(x_poly)
  df['Predicted_Y'] = y_pred
  plt.plot(x, y_pred)
  y_pred = y_pred[0:80]
  
  #"""
  #R^2 and MSE of training data set
  avgX = np.mean(X_train) 
  avgY = np.mean(Y_train)
  SSR1 = sum((Y_train-y_pred)*(Y_train-y_pred))
  SST1 = sum((Y_train-avgY)*(Y_train-avgY))
  Rsqr1 = 1 - SSR1/SST1 
  print("R^2 of training dataset #", i ,": ", Rsqr1)
  MSE1 = SSR1/len(Y_train)
  print("Mean Squared Error of training dataset #", i ,": ", MSE1)
  
  #R^2 and MSE of test data set
  avgXtest = np.mean(X_test)
  avgYtest = np.mean(Y_test)
  SSR = sum((Y_test-y_pred)*(Y_test-y_pred))
  SST = sum((Y_test-avgYtest)*(Y_test-avgYtest))
  Rsqr = 1 - SSR/SST 
  print("R^2 of test dataset #", i ,": ", Rsqr)
  MSE = SSR/len(Y_test)
  print("Mean Squared Error of test dataset #", i ,": ", MSE)
  #"""
  i+=1
  
plt.show()
