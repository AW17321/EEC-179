import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

m = 0;
c = 0;
L = 0.0001;

#1. Generate random dataset
x = np.random.rand(100, 1)
y = 10 + 5 * x + np.random.normal(0, 1, (100, 1))

#2. Plot random linear scatter plot
plt.scatter(x, y) 
plt.plot(x, y, 'o') 

#3 Split dataset
X_train = x[0:80]
X_test = x[80:100]
Y_train = y[0:80]
Y_test = y[80:100]

i = 0;

while i < 10000:
  D_m = (-2/len(X_train))*sum(X_train*(Y_train-(m*X_train + c)))
  D_c = (-2/len(X_train))*sum((Y_train-(m*X_train + c)))
  m = m - L*D_m
  c = c - L*D_c
  i+=1

print(m)
print(c)
plt.plot(X_train, m*X_train + c, ls = '-')
plt.show()

#R^2 and MSE of training data set
avgX = np.mean(X_train) 
avgY = np.mean(Y_train)
SSR1 = sum((Y_train-(m*X_train+c))*(Y_train-(m*X_train+c)))
SST1 = sum((Y_train-avgY)*(Y_train-avgY))
Rsqr1 = 1 - SSR1/SST1 
print("R^2 of training dataset: ", Rsqr1)
MSE1 = SSR1/len(Y_train)
print("Mean Squared Error of training dataset: ", MSE1)

#R^2 and MSE of test data set
avgXtest = np.mean(X_test)
avgYtest = np.mean(Y_test)
SSR = sum((Y_test-(m*X_test+c))*(Y_test-(m*X_test+c)))
SST = sum((Y_test-avgYtest)*(Y_test-avgYtest))
Rsqr = 1 - SSR/SST 
print("R^2 of test dataset: ", Rsqr)
MSE = SSR/len(Y_test)
print("Mean Squared Error of test dataset: ", MSE)

#I tested 100000 iterations and the r^2 values were much better
